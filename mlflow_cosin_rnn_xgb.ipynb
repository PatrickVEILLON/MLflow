{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12cbaf25-a7dc-43f6-b747-3bb02fe0af96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import libraries\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MlflowClient\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "from mlflow import MlflowClient\n",
    "import mlflow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as pp\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense,  Activation, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define tracking_uri\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Define experiment name, run name and artifact_path name\n",
    "meteo_mean_experiment = mlflow.set_experiment(\"Meteo_cosin_rnn_xgb\")\n",
    "run_name = \"rnn_xgb1\"\n",
    "artifact_path = \"rnn_xgb_cosin\"\n",
    "\n",
    "# Import database\n",
    "\n",
    "df = pd.read_csv('df_full_cosin.csv', sep=',', header=0)\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.sort_values(by = 'Date')\n",
    "df = df.drop([\"Date\", \"Location\"], axis = 1)\n",
    "#df = df.drop([\"Cluster\"], axis = 1)\n",
    "df[\"RainTomorrow\"]  = df[\"RainTomorrow\"].astype(np.int8)\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "target = df['RainTomorrow']\n",
    "data = df.drop('RainTomorrow', axis=1)\n",
    "\n",
    "encoder =  LabelEncoder()\n",
    "target = encoder.fit_transform(target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, shuffle=False)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#smo = SMOTE()\n",
    "#X_sm, y_sm = smo.fit_resample(X_train, y_train)\n",
    "\n",
    "#rOs = RandomOverSampler()\n",
    "#X_sm, y_sm = rOs.fit_resample(X_train, y_train)\n",
    "\n",
    "#rUs = RandomUnderSampler()\n",
    "#X_sm, y_sm = rUs.fit_resample(X_train, y_train)\n",
    "\n",
    "#cc = ClusterCentroids()\n",
    "#X_sm, y_sm = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train model\n",
    "\n",
    "inputs = Input(shape = (24), name = \"Input\")\n",
    "dense1 = Dense(units = 24, activation = \"tanh\", name = \"Couche_1\")\n",
    "dense2 = Dense(units = 16, activation = \"tanh\", name = \"Couche_2\")\n",
    "dense3 = Dense(units = 10, activation = \"tanh\", name = \"Couche_3\")\n",
    "dense4 = Dense(units = 6, activation = \"tanh\", name = \"Couche_4\")\n",
    "dense5 = Dense(units = 1, activation = 'sigmoid', name = \"Couche_5\")\n",
    "\n",
    "\"\"\"\n",
    "con1\n",
    "inputs = Input(shape = (24), name = \"Input\")\n",
    "dense1 = Dense(units = 24, activation = \"relu\", name = \"Couche_1\")\n",
    "dense2 = Dense(units = 16, activation = \"relu\", name = \"Couche_2\")\n",
    "dense3 = Dense(units = 10, activation = \"relu\", name = \"Couche_3\")\n",
    "dense4 = Dense(units = 1, activation = 'sigmoid', name = \"Couche_4\")\n",
    "\n",
    "con2\n",
    "inputs = Input(shape = (24), name = \"Input\")\n",
    "dense1 = Dense(units = 24, activation = \"relu\", name = \"Couche_1\")\n",
    "dense2 = Dense(units = 16, activation = \"relu\", name = \"Couche_2\")\n",
    "dense3 = Dense(units = 10, activation = \"relu\", name = \"Couche_3\")\n",
    "dense4 = Dense(units = 6, activation = \"relu\", name = \"Couche_4\")\n",
    "dense5 = Dense(units = 1, activation = 'sigmoid', name = \"Couche_5\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "x = dense1(inputs)\n",
    "x = dense2(x)\n",
    "x = dense3(x)\n",
    "x = dense4(x)\n",
    "outputs = dense5(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "#model.summary()\n",
    "\n",
    "params = {\n",
    "    \"loss\": 'BinaryCrossentropy',\n",
    "    'optimizer': 'Adam(learning_rate=0.001)',\n",
    "    'metrics': 'accuracy',\n",
    "    'epochs': 500,\n",
    "    'batch_size': 32,\n",
    "    'validation_split': 0.2\n",
    "}\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                    min_delta = 0.01,\n",
    "                    patience = 5,\n",
    "                    verbose = 1,\n",
    "                    restore_best_weights = True,\n",
    "                    mode='min')\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss =\"BinaryCrossentropy\",\n",
    "              optimizer = opt,\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 500, batch_size = 32, validation_split = 0.2, callbacks = [early_stopping])\n",
    "\n",
    "#test_pred = model.predict(X_test)\n",
    "#print(test_pred)\n",
    "#y_test_class = y_test\n",
    "#y_test_class = y_test_class.apply(lambda val: int(val))\n",
    "#print(y_test_class)\n",
    "\n",
    "#y_pred_class = np.where(test_pred >= 0.5, 1, 0)\n",
    "#y_pred_class = np.concatenate(y_pred_class).ravel().tolist()\n",
    "#print(y_pred_class)\n",
    "\n",
    "# Get output from model\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[2].output)\n",
    "X_train_features = intermediate_layer_model.predict(X_train)\n",
    "X_test_features = intermediate_layer_model.predict(X_test)\n",
    "\n",
    "# XGB \n",
    "\n",
    "params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    'max_depth': 8,\n",
    "    'n_estimators': 500\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.05, max_depth=8, n_estimators=500)\n",
    "\n",
    "# Evaluate model\n",
    "\n",
    "xgb.fit(X_train_features, y_train)\n",
    "\n",
    "preds = xgb.predict(X_test_features)\n",
    "\n",
    "# Evaluate model\n",
    "\n",
    "co = pd.crosstab(y_test, preds, rownames=['Classe réelle'], colnames=['Classe prédite'])\n",
    "display(co)\n",
    "\n",
    "cr = classification_report(y_test, preds, output_dict=True)\n",
    "cra = pd.DataFrame(cr).transpose()\n",
    "display(cra)\n",
    "\n",
    "tp_1 = co.iloc[1,1]\n",
    "tn_0 = co.iloc[0,0]\n",
    "fp_1 = co.iloc[0,1]\n",
    "fn_0 = co.iloc[1,0]\n",
    "prec_0 = cra.iloc[0,0]\n",
    "prec_1 = cra.iloc[1,0]\n",
    "rec_0 = cra.iloc[0,1]\n",
    "rec_1 = cra.iloc[1,1]\n",
    "f1_0 = cra.iloc[0,2]\n",
    "f1_1 = cra.iloc[1,2]\n",
    "acc = cra.iloc[2,0]\n",
    "metrics = {\"vrai positifs pred 1\": tp_1, \"vrai négatifs pred 0\": tn_0, \"faux positifs pred 1\": fp_1, \"faux négatifs pred 0\": fn_0, 'précision 0': prec_0, 'précision 1': prec_1, 'recall 0': rec_0, 'recall 1': rec_1, 'f1 0': f1_0, 'f1_1': f1_1, 'accuracy': acc}\n",
    "\n",
    "# Store information in tracking server\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model, input_example=X_test, artifact_path=artifact_path\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59547400-84b0-437a-969f-acec84b5c459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
